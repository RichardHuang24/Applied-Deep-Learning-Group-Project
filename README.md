# ðŸ¾ WSSS Framework

A **Weakly-Supervised Semantic Segmentation** framework for training and evaluating segmentation models using CAM-based pseudo-labels and partial supervision.

## ðŸ“Œ Overview

This framework implements a full pipeline for Weakly-Supervised Semantic Segmentation:

1. Training an image classifier with various backbones and initialization methods.
2. Generating Class Activation Maps (CAMs) using different techniques (e.g., Grad-CAM, CCAM).
3. Creating pseudo-masks from the activation maps.
4. Training a segmentation model using the pseudo-masks.
5. Evaluating the segmentation performance with standard metrics.

---

## âš™ï¸ Installation

### Requirements

- Python 3.6+
- PyTorch 1.7+
- CUDA (recommended for faster training)
- **Additional dependencies**:  
  Only 3 allowed in this minimal setup:  
  - `torch`  
  - `torchvision`  
  - `opencv-python`

(Use optional tools like PIL, tqdm, numpy, matplotlib for more advanced visualization if constraints allow.)

---

### ðŸ”§ Setup

#### Clone the repository

```bash
git clone https://github.com/RichardHuang24/Applied-Deep-Learning-Group-Project.git
cd Applied-Deep-Learning-Group-Project
```

#### Create a virtual environment (optional but recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

#### Install dependencies

```bash
pip install -r requirements.txt
```

---

## ðŸ“ Dataset

This framework is configured to work with **Oxford-IIIT Pet Dataset**.

Download the dataset with:

```bash
python main.py --download-only
```

This will download the dataset to the location specified in your config file.

---

## ðŸš€ Running Experiments

### Basic Usage

To run a single experiment with default settings:

```bash
python main.py
```

---

### Customizing Experiments

Customize experiments with the following options:

```bash
python main.py --backbone resnet50 --init imagenet --cam gradcam
```

#### âœ… Available Options

- `--config`: Path to configuration file (default: `"config.json"`)
- `--backbone`: Backbone architecture (choices: `"resnet18"`, `"resnet34"`, `"resnet50"`)
- `--init`: Initialization method (choices: `"simclr"`, `"imagenet"`, `"random"`)
- `--cam`: CAM method (choices: `"gradcam"`, `"ccam"`; default is `"gradcam"`)
- `--all`: Run **all** combinations of experiments
- `--download`: Download dataset before running experiments
- `--download-only`: Only download dataset
- `--output`: Custom output directory

---

### ðŸ§ª Common Use Cases

#### Run a Fast Test Experiment

```bash
python main.py --backbone resnet18 --init random --cam gradcam
```

#### Run a High-Performance Configuration

```bash
python main.py --backbone resnet50 --init imagenet --cam ccam
```

#### Run All Possible Combinations

```bash
python main.py --all
```

#### Download Dataset and Run

```bash
python main.py --download --backbone resnet50 --init imagenet --cam gradcam
```

---

## ðŸ“¦ Understanding the Output

For each experiment, the following outputs are generated:

1. **Classifier Model**: Trained image classifier
2. **CAM Model**: Class Activation Map generator
3. **Generated Masks**: Pseudo-masks from CAMs
4. **Segmentation Model**: Final segmentation model (e.g., PSPNet)
5. **Evaluation Results**: mIoU and pixel accuracy scores
6. **Experiment Summary**: Visual and JSON summary

#### Output Directory Structure:

```
experiments/
â””â”€â”€ resnet50_imagenet_gradcam_20230415_120000/
    â”œâ”€â”€ classifier/
    â”œâ”€â”€ cam_model/
    â”œâ”€â”€ masks/
    â”‚   â””â”€â”€ visualizations/
    â”œâ”€â”€ segmentation/
    â”œâ”€â”€ evaluation/
    â”œâ”€â”€ experiment_config.json
    â”œâ”€â”€ results.json
    â”œâ”€â”€ experiment_summary.png
    â””â”€â”€ experiment.log
```

---

## ðŸ“Š Metrics

The framework evaluates segmentation performance using:

- **Pixel Accuracy**: Percentage of correctly classified pixels.
- **Mean IoU (mIoU)**: Average Intersection over Union across all classes.

All results are automatically saved to `results/metrics_table.csv`.

---

## ðŸ§ª Experiment Workflow Example

```bash
# 1. Download the dataset
python main.py --download-only

# 2. Run a test experiment
python main.py --backbone resnet18 --init random --cam gradcam

# 3. Run a high-performance configuration
python main.py --backbone resnet50 --init imagenet --cam ccam

# 4. Compare all methods
python main.py --all
```

---

## ðŸ“‚ Project Structure

```
â”œâ”€â”€ main.py                  # Main runner
â”œâ”€â”€ train.py                 # Training pipeline
â”œâ”€â”€ generate_masks.py        # CAM mask generation
â”œâ”€â”€ evaluate.py              # Evaluation utilities
â”œâ”€â”€ utils/                   # Utility functions
â”‚   â””â”€â”€ download.py          # Dataset utils
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ classifier/          # ResNet-based classifiers
â”‚   â”œâ”€â”€ cam/                 # CAM methods: GradCAM, CCAM
â”‚   â””â”€â”€ segmentation/        # PSPNet (semantic segmentation)
â”œâ”€â”€ data/                    # Dataset handling
â”œâ”€â”€ config.json              # Default experiment configuration
â””â”€â”€ requirements.txt         # Dependencies
```

---

## ðŸ“œ Citing

If you use this framework in your research or coursework, please cite this repository:

> GitHub: [RichardHuang24/Applied-Deep-Learning-Group-Project](https://github.com/RichardHuang24/Applied-Deep-Learning-Group-Project)

---

Happy segmenting! ðŸŽ¯
