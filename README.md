# ðŸ¾ WSSS Framework

A **Weakly-Supervised Semantic Segmentation** framework for training and evaluating segmentation models using CAM-based pseudo-labels and partial or full supervision.

---

## ðŸ“Œ Overview

This framework implements a modular pipeline for weakly-supervised semantic segmentation using the Oxford-IIIT Pet dataset. It supports:
- Training classifiers with various backbones and initialization types
- Generating Class Activation Maps (CAMs)
- Converting CAMs to pseudo segmentation masks
- Training segmentation models using weak or full supervision
- Evaluation and result aggregation

All components are accessible via command-line interfaces in `main.py`.

---

## âš™ï¸ Installation

### Requirements

- Python 3.6+
- PyTorch 1.7+
- CUDA (recommended for faster training)
- **Additional dependencies**:  
  - `tqdm`  

---

### ðŸ”§ Setup

#### Clone the repository

```bash
git clone https://github.com/RichardHuang24/Applied-Deep-Learning-Group-Project.git
cd Applied-Deep-Learning-Group-Project
```

#### Create a virtual environment (optional but recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

---

## ðŸ“ Dataset

This framework is configured to work with the **Oxford-IIIT Pet Dataset**.

To download the dataset, run:

```bash
python main.py download
```

---

## ðŸš€ Running Experiments

**Note**: This framework uses `ResNet-50` as the default and only backbone for all classification models.

**Full Supervision**: For full supervision mode (`--supervision full`), the segmentation model is trained using ground-truth pixel masks without relying on CAM-generated pseudo-labels.

All commands below are available via `main.py`. You can run individual steps or the entire pipeline.

---

### ðŸ”¹ Step 1: Train a Classifier

```bash
python main.py train_classifier        --init imagenet     --cam gradcam     --experiment_name example_exp
```

---

### ðŸ”¹ Step 2: Generate CAM-based Pseudo Masks

```bash
python main.py generate_masks          --init imagenet     --cam cam+ccam       --experiment_name example_exp
```

---

### ðŸ”¹ Step 3: Train the Segmentation Model

```bash
python main.py train_segmentation     --supervision weak_gradcam     --init imagenet     --cam gradcam     --experiment_name example_exp
```

---

### ðŸ”¹ Step 4: Evaluate Segmentation Performance

```bash
python main.py evaluate     --supervision weak_gradcam     --init imagenet     --cam gradcam     --experiment_name example_exp
```

---

### ðŸ”¹ Combined Step: Train Classifier + Generate CAM Masks

```bash
python main.py train_and_generate      --init imagenet     --cam gradcam+ccam     --experiment_name example_exp
```

---

### ðŸ”¹ Run Full Pipeline

**ðŸ”¸ Weakly-Supervised Example (GradCAM):**
```bash
python main.py run_all \
    --init imagenet \
    --cam gradcam \
    --supervision weak_gradcam \
    --experiment_name example_exp
```

**ðŸ”¸ Fully-Supervised Example (Ground Truth Masks):**
```bash
python main.py run_all \
    --init imagenet \
    --supervision full \
    --experiment_name full_supervision_exp
```


---

## âš™ï¸ Customization Options

| Option         | Values                                             | Description                      |
|----------------|-----------------------------------------------------|----------------------------------|
| `--init`       | `random`, `mocov2`, `imagenet`                     | Initialization method            |
| `--cam`        | `gradcam`, `cam`, `ccam`, `gradcam+ccam`, `cam+ccam` | CAM methods                      |
| `--supervision`| `full`, `weak_gradcam`, `weak_cam`                 | Supervision type                 |

---

## ðŸ“¦ Understanding the Output

For each experiment, the following outputs are generated:

1. **Classifier Model**: Trained image classifier
2. **CAM Model**: Class Activation Map generator
3. **Generated Masks**: Pseudo-masks from CAMs
4. **Segmentation Model**: Final segmentation model (e.g., PSPNet)
5. **Evaluation Results**: mIoU and pixel accuracy scores
6. **Experiment Summary**: Visual and JSON summary

## ðŸ“¦ Output Structure

```
outputs/
â””â”€â”€ example_exp/
    â”œâ”€â”€ classifier/
    â”œâ”€â”€ masks/
    â”œâ”€â”€ segmentation/
    â”œâ”€â”€ evaluation/
    â”œâ”€â”€ experiment_config.json
    â””â”€â”€ results.json
```

---

## ðŸ“Š Metrics

The framework evaluates segmentation performance using:

- **Pixel Accuracy**: Percentage of correctly classified pixels.
- **Mean IoU (mIoU)**: Average Intersection over Union across all classes.


---

## ðŸ“‚ Project Structure

```
â”œâ”€â”€ main.py
â”œâ”€â”€ train.py
â”œâ”€â”€ generate_masks.py
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ data.py

â”œâ”€â”€ handlers/
â”‚   â”œâ”€â”€ classifier.py
â”‚   â”œâ”€â”€ segmentation.py
â”‚   â”œâ”€â”€ masks.py
â”‚   â””â”€â”€ evaluate.py

â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ classifier.py
â”‚   â”œâ”€â”€ cam.py
â”‚   â””â”€â”€ pspnet.py

â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ download.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ visualization.py
â”‚   â””â”€â”€ logging.py

â”œâ”€â”€ config.json
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```


---

## ðŸ“œ Citation

> GitHub: [RichardHuang24/Applied-Deep-Learning-Group-Project](https://github.com/RichardHuang24/Applied-Deep-Learning-Group-Project)

